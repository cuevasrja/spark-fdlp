{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": [
     "Create SparkSession"
    ]
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.remote(\"sc://192.168.2.20:15002\").getOrCreate()\n",
    "\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "\n",
    "explicitSchema = StructType([\n",
    "StructField(\"DEST_COUNTRY_NAME\", StringType(), False),\n",
    "StructField(\"ORIGIN_COUNTRY_NAME\", StringType(), False),\n",
    "StructField(\"count\", LongType(), False, metadata={\"hello\":\"world\"})\n",
    "])\n",
    "\n",
    "df = spark\\\n",
    "    .read\\\n",
    "    .format(\"json\")\\\n",
    "    .schema(explicitSchema)\\\n",
    "    .load(\"datasets/2015-summary.json\")\n",
    "    \n",
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|numberOne|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "|    United States|            Romania|   15|        1|\n",
      "|    United States|            Croatia|    1|        1|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|  Destination|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|United States|\n",
      "|    United States|            Croatia|    1|United States|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, column, expr, lit\n",
    "\n",
    "# SELECT *, 1 as numberOne FROM dfTable LIMIT 2\n",
    "df.withColumn(\"numberOne\", lit(1)).show(2)\n",
    "\n",
    "# SELECT *, ORIGIN_COUNTRY_NAME == DEST_COUNTRY_NAME as withinCountry FROM dfTable LIMIT 2\n",
    "df.withColumn(\"withinCountry\", expr(\"ORIGIN_COUNTRY_NAME == DEST_COUNTRY_NAME\")).show(2)\n",
    "\n",
    "# SELECT *, DEST_COUNTRY_NAME as Destination FROM dfTable LIMIT 2\n",
    "df.withColumn(\"Destination\", col(\"DEST_COUNTRY_NAME\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "2"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dest', 'ORIGIN_COUNTRY_NAME', 'count']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumnRenamed(\"DEST_COUNTRY_NAME\", \"dest\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "3"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------+\n",
      "|This Long Column-Name|new col|\n",
      "+---------------------+-------+\n",
      "|              Romania|Romania|\n",
      "|              Croatia|Croatia|\n",
      "+---------------------+-------+\n",
      "only showing top 2 rows\n",
      "\n",
      "['This Long Column-Name']\n",
      "['This Long Column-Name']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'false'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# No escape quotes\n",
    "dfWithLongColName = df.withColumn(\n",
    "    \"This Long Column-Name\", \n",
    "    expr(\"ORIGIN_COUNTRY_NAME\"))\n",
    "\n",
    "# Escape quotes\n",
    "dfWithLongColName.selectExpr(\n",
    "    \"`This Long Column-Name`\",\n",
    "    \"`This Long Column-Name` as `new col`\")\\\n",
    "    .show(2)\n",
    "    \n",
    "print(dfWithLongColName.select(col(\"This Long Column-Name\")).columns)\n",
    "print(dfWithLongColName.select(expr(\"`This Long Column-Name`\")).columns)\n",
    "\n",
    "# Nota: Spark es case-insensitive\n",
    "spark.conf.get(\"spark.sql.caseSensitive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "4"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DEST_COUNTRY_NAME', 'count']\n",
      "['count', 'This Long Column-Name']\n",
      "['DEST_COUNTRY_NAME', 'ORIGIN_COUNTRY_NAME', 'count', 'This Long Column-Name']\n"
     ]
    }
   ],
   "source": [
    "print(df.drop(\"ORIGIN_COUNTRY_NAME\").columns)\n",
    "\n",
    "print(dfWithLongColName.drop(\"ORIGIN_COUNTRY_NAME\", \"DEST_COUNTRY_NAME\").columns)\n",
    "\n",
    "print(dfWithLongColName.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "5"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|count2|\n",
      "+-----------------+-------------------+-----+------+\n",
      "|    United States|            Romania|   15|  15.0|\n",
      "|    United States|            Croatia|    1|   1.0|\n",
      "+-----------------+-------------------+-----+------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+-----+------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|count2|\n",
      "+-----------------+-------------------+-----+------+\n",
      "|    United States|            Romania|   15|  15.0|\n",
      "|    United States|            Croatia|    1|   1.0|\n",
      "+-----------------+-------------------+-----+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"count2\", col(\"count\").cast(\"float\")).show(2)\n",
    "\n",
    "spark.sql(\"SELECT *, cast(count as float) AS count2 FROM dfTable\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "6"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|          Singapore|    1|\n",
      "|          Moldova|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"count\") < 2).show(2)\n",
    "\n",
    "df.where(\"count < 2\").show(2)\n",
    "\n",
    "# SELECT * FROM dfTable WHERE count < 2 AND ORIGIN_COUNTRY_NAME != \"Croatia\" LIMIT 2\n",
    "df.where(col(\"count\") < 2).where(col(\"ORIGIN_COUNTRY_NAME\") != \"Croatia\")\\\n",
    " .show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "7"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "125\n"
     ]
    }
   ],
   "source": [
    "# SELECT COUNT(DISTINCT(ORIGIN_COUNTRY_NAME, DEST_COUNTRY_NAME)) FROM dfTable\n",
    "print(df.select(\"ORIGIN_COUNTRY_NAME\", \"DEST_COUNTRY_NAME\").distinct().count())\n",
    "\n",
    "# SELECT COUNT(DISTINCT ORIGIN_COUNTRY_NAME) FROM dfTable\n",
    "print(df.select(\"ORIGIN_COUNTRY_NAME\").distinct().count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "8"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "seed = 5 # random.randint(0, 100)\n",
    "withReplacement = False\n",
    "fraction = 0.5\n",
    "df.sample(withReplacement, fraction, seed).show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": [
     "9"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71, 67, 65, 53]\n"
     ]
    }
   ],
   "source": [
    "dataFrames = df.randomSplit([0.25, 0.25, 0.25, 0.25], seed)\n",
    "\n",
    "print([df.count() for df in dataFrames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": [
     "10"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+---+\n",
      "|NAME|LAST_NAME|AGE|\n",
      "+----+---------+---+\n",
      "|John|      Doe| 25|\n",
      "|Jane|      Doe| 22|\n",
      "|Jill|      Doe| 20|\n",
      "|Jack|      Doe| 18|\n",
      "| Doe|     John| 25|\n",
      "| Doe|     Jane| 22|\n",
      "| Doe|     Jill| 20|\n",
      "| Doe|     Jack| 18|\n",
      "+----+---------+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StructType([StructField('NAME', StringType(), True), StructField('AGE', StringType(), True), StructField('LAST_NAME', StringType(), True)])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "\n",
    "schema0 = StructType([\n",
    "    StructField(\"NAME\", StringType(), True),\n",
    "    StructField(\"LAST_NAME\", StringType(), True),\n",
    "    StructField(\"AGE\", LongType(), False)\n",
    "])\n",
    "\n",
    "rows0 = [\n",
    "    Row(\"John\", \"Doe\", 25),\n",
    "    Row(\"Jane\", \"Doe\", 22),\n",
    "    Row(\"Jill\", \"Doe\", 20),\n",
    "    Row(\"Jack\", \"Doe\", 18)\n",
    "]\n",
    "\n",
    "schema1 = StructType([\n",
    "    StructField(\"LAST_NAME\", StringType(), True),\n",
    "    StructField(\"NAME\", StringType(), True),\n",
    "    StructField(\"AGE\", LongType(), False)\n",
    "])\n",
    "\n",
    "rows1 = [\n",
    "    Row(\"Doe\", \"John\", 25),\n",
    "    Row(\"Doe\", \"Jane\", 22),\n",
    "    Row(\"Doe\", \"Jill\", 20),\n",
    "    Row(\"Doe\", \"Jack\", 18)\n",
    "]\n",
    "\n",
    "schema2 = StructType([\n",
    "    StructField(\"NAME\", StringType(), True),\n",
    "    StructField(\"AGE\", LongType(), False),\n",
    "    StructField(\"LAST_NAME\", StringType(), True)\n",
    "])\n",
    "\n",
    "rows2 = [\n",
    "    Row(\"John\", 25, \"Doe\"),\n",
    "    Row(\"Jane\", 22, \"Doe\"),\n",
    "    Row(\"Jill\", 20, \"Doe\"),\n",
    "    Row(\"Jack\", 18, \"Doe\")\n",
    "]\n",
    "\n",
    "df0 = spark.createDataFrame(rows0, schema0)\n",
    "df1 = spark.createDataFrame(rows1, schema1)\n",
    "df2 = spark.createDataFrame(rows2, schema2)\n",
    "\n",
    "# Union df0 and df1\n",
    "df0.union(df1).show()\n",
    "\n",
    "# Union df2 and df1\n",
    "df2.union(df1).schema\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": [
     "11"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|               Malta|      United States|    1|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|          Gibraltar|    1|\n",
      "|       United States|          Singapore|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|     Burkina Faso|      United States|    1|\n",
      "|    Cote d'Ivoire|      United States|    1|\n",
      "|           Cyprus|      United States|    1|\n",
      "|         Djibouti|      United States|    1|\n",
      "|        Indonesia|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|     Burkina Faso|      United States|    1|\n",
      "|    Cote d'Ivoire|      United States|    1|\n",
      "|           Cyprus|      United States|    1|\n",
      "|         Djibouti|      United States|    1|\n",
      "|        Indonesia|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(\"count\").show(5)\n",
    "df.orderBy(\"count\", \"DEST_COUNTRY_NAME\").show(5)\n",
    "df.orderBy(col(\"count\"), col(\"DEST_COUNTRY_NAME\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "tags": [
     "12"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|          Moldova|      United States|    1|\n",
      "|    United States|            Croatia|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|\n",
      "+-----------------+-------------------+------+\n",
      "|    United States|      United States|370002|\n",
      "|    United States|             Canada|  8483|\n",
      "+-----------------+-------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# SELECT * FROM dfTable ORDER BY count DESC LIMIT 2\n",
    "df.orderBy(expr(\"count desc\")).show(2) # Preguntar por qué no funciona con \"count desc\"\n",
    "\n",
    "# SELECT * FROM dfTable ORDER BY count DESC, DEST_COUNTRY_NAME ASC LIMIT 2\n",
    "df.orderBy(col(\"count\").desc(), col(\"DEST_COUNTRY_NAME\").asc()).show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "tags": [
     "13"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SELECT * FROM dfTable LIMIT 6\n",
    "df.limit(5).show() # Preguntar diferencia entre limit y show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "tags": [
     "14"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Exchange RoundRobinPartitioning(10), REPARTITION_BY_NUM, [plan_id=7544]\n",
      "   +- FileScan json [DEST_COUNTRY_NAME#10723,ORIGIN_COUNTRY_NAME#10724,count#10725L] Batched: false, DataFilters: [], Format: JSON, Location: InMemoryFileIndex(1 paths)[hdfs://node-master:9000/user/hadoop/datasets/2015-summary.json], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:bigint>\n",
      "\n",
      "\n",
      "None\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Exchange hashpartitioning(DEST_COUNTRY_NAME#10733, 200), REPARTITION_BY_COL, [plan_id=7552]\n",
      "   +- FileScan json [DEST_COUNTRY_NAME#10733,ORIGIN_COUNTRY_NAME#10734,count#10735L] Batched: false, DataFilters: [], Format: JSON, Location: InMemoryFileIndex(1 paths)[hdfs://node-master:9000/user/hadoop/datasets/2015-summary.json], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:bigint>\n",
      "\n",
      "\n",
      "None\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Exchange hashpartitioning(DEST_COUNTRY_NAME#10744, 5), REPARTITION_BY_NUM, [plan_id=7560]\n",
      "   +- FileScan json [DEST_COUNTRY_NAME#10744,ORIGIN_COUNTRY_NAME#10745,count#10746L] Batched: false, DataFilters: [], Format: JSON, Location: InMemoryFileIndex(1 paths)[hdfs://node-master:9000/user/hadoop/datasets/2015-summary.json], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:bigint>\n",
      "\n",
      "\n",
      "None\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Coalesce 2\n",
      "   +- Exchange hashpartitioning(DEST_COUNTRY_NAME#10755, 5), REPARTITION_BY_NUM, [plan_id=7571]\n",
      "      +- FileScan json [DEST_COUNTRY_NAME#10755,ORIGIN_COUNTRY_NAME#10756,count#10757L] Batched: false, DataFilters: [], Format: JSON, Location: InMemoryFileIndex(1 paths)[hdfs://node-master:9000/user/hadoop/datasets/2015-summary.json], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:bigint>\n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.repartition(10).explain())\n",
    "\n",
    "print(df.repartition(col(\"DEST_COUNTRY_NAME\")).explain())\n",
    "\n",
    "print(df.repartition(5, col(\"DEST_COUNTRY_NAME\")).explain())\n",
    "\n",
    "print(df.repartition(5, col(\"DEST_COUNTRY_NAME\")).coalesce(2).explain())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "|    United States|          Singapore|    1|\n",
      "|    United States|            Grenada|   62|\n",
      "|       Costa Rica|      United States|  588|\n",
      "|          Senegal|      United States|   40|\n",
      "|          Moldova|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |15   |\n",
      "|United States    |Croatia            |1    |\n",
      "|United States    |Ireland            |344  |\n",
      "|Egypt            |United States      |15   |\n",
      "|United States    |India              |62   |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=344),\n",
       " Row(DEST_COUNTRY_NAME='Egypt', ORIGIN_COUNTRY_NAME='United States', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='India', count=62),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Singapore', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Grenada', count=62),\n",
       " Row(DEST_COUNTRY_NAME='Costa Rica', ORIGIN_COUNTRY_NAME='United States', count=588),\n",
       " Row(DEST_COUNTRY_NAME='Senegal', ORIGIN_COUNTRY_NAME='United States', count=40),\n",
       " Row(DEST_COUNTRY_NAME='Moldova', ORIGIN_COUNTRY_NAME='United States', count=1)]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collectDF = df.limit(10)\n",
    "collectDF.take(5) # take works with an Integer count\n",
    "collectDF.show() # this prints it out nicely\n",
    "collectDF.show(5, False)\n",
    "collectDF.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
