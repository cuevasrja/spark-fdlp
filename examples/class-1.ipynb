{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "Create SparkSession"
    ]
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.remote(\"sc://192.168.2.20:15002\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "1"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('DEST_COUNTRY_NAME', StringType(), True), StructField('ORIGIN_COUNTRY_NAME', StringType(), True), StructField('count', StringType(), True)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark\\\n",
    "    .read\\\n",
    "    .format(\"json\")\\\n",
    "    .load(\"datasets/2015-summary.json\")\n",
    "    \n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "2"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('DEST_COUNTRY_NAME', StringType(), True), StructField('ORIGIN_COUNTRY_NAME', StringType(), True), StructField('count', LongType(), True)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "\n",
    "explicitSchema = StructType([\n",
    "StructField(\"DEST_COUNTRY_NAME\", StringType(), False),\n",
    "StructField(\"ORIGIN_COUNTRY_NAME\", StringType(), False),\n",
    "StructField(\"count\", LongType(), False, metadata={\"hello\":\"world\"})\n",
    "])\n",
    "\n",
    "edf = spark\\\n",
    "    .read\\\n",
    "    .format(\"json\")\\\n",
    "    .schema(explicitSchema)\\\n",
    "    .load(\"datasets/2015-summary.json\")\n",
    "\n",
    "edf.schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "3"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<'columnaChiquitita'>\n",
      "Column<'DEST_COUNTRY_NAME'>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, column\n",
    "\n",
    "cc = col(\"columnaChiquitita\")\n",
    "cg = column(\"columnaGrandotota\")\n",
    "\n",
    "print(cc)\n",
    "print(edf.DEST_COUNTRY_NAME)\n",
    "\n",
    "#edf.select(col(\"DEST_COUNTRY_NAME\"), column(\"ORIGIN_COUNTRY_NAME\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "4"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----------+-----------------------------------+\n",
      "|(count - 5)|(count - 5)|(count - 5)|((((count - 5) * 200) - 6) < count)|\n",
      "+-----------+-----------+-----------+-----------------------------------+\n",
      "|         10|         10|         10|                              false|\n",
      "|         -4|         -4|         -4|                               true|\n",
      "|        339|        339|        339|                              false|\n",
      "|         10|         10|         10|                              false|\n",
      "|         57|         57|         57|                              false|\n",
      "|         -4|         -4|         -4|                               true|\n",
      "|         57|         57|         57|                              false|\n",
      "|        583|        583|        583|                              false|\n",
      "|         35|         35|         35|                              false|\n",
      "|         -4|         -4|         -4|                               true|\n",
      "+-----------+-----------+-----------+-----------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Column<'None'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr, col\n",
    "\n",
    "#expr(\"count - 5\")\n",
    "#col(\"count\") - 5\n",
    "#expr(\"count\") - 5\n",
    "\n",
    "edf.select(expr(\"count\") - 5,expr(\"count - 5\"), col(\"count\") - 5, (((col(\"count\") - 5) * 200) - 6) < col(\"count\")).show(10)\n",
    "\n",
    "(((col(\"count\") - 5) * 200) - 6) < col(\"count\")\n",
    "#expr(\"(((count - 5) * 200) - 6) < count\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "5"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15)\n",
      "<Row('Hello', None, 1, False)> Hello None 1 False\n"
     ]
    }
   ],
   "source": [
    "print(edf.first())\n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "myRow = Row(\"Hello\", None, 1, False)\n",
    "print(myRow, myRow[0], myRow[1], myRow[2], myRow[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": [
     "6"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+\n",
      "| some| col|names|\n",
      "+-----+----+-----+\n",
      "|Hello|NULL|    1|\n",
      "+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "\n",
    "myManualSchema = StructType([\n",
    "StructField(\"some\", StringType(), True),\n",
    "StructField(\"col\", StringType(), True),\n",
    "StructField(\"names\", LongType(), False)\n",
    "])\n",
    "\n",
    "myRow = Row(\"Hello\", None, 1)\n",
    "myDf = spark.createDataFrame([myRow], myManualSchema)\n",
    "\n",
    "myDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": [
     "7"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|\n",
      "+-----------------+-------------------+\n",
      "|    United States|            Romania|\n",
      "|    United States|            Croatia|\n",
      "+-----------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-----------------+-----------------+\n",
      "|DEST_COUNTRY_NAME|DEST_COUNTRY_NAME|DEST_COUNTRY_NAME|\n",
      "+-----------------+-----------------+-----------------+\n",
      "|    United States|    United States|    United States|\n",
      "|    United States|    United States|    United States|\n",
      "+-----------------+-----------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edf.createOrReplaceTempView(\"edf\")\n",
    "\n",
    "# spark.sql(\"SELECT * FROM edf\").show(2)\n",
    "# spark.sql(\"SELECT DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME, count FROM edf\").show(2)\n",
    "# spark.sql(\"SELECT DEST_COUNTRY_NAME as destination, ORIGIN_COUNTRY_NAME as origin, count * 10 FROM edf\").show(2)\n",
    "\n",
    "# spark.sql(\"SELECT DEST_COUNTRY_NAME FROM edf\").show(2)\n",
    "edf.select(\"DEST_COUNTRY_NAME\").show(2)\n",
    "\n",
    "# spark.sql(\"SELECT DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME FROM edf\").show(2)\n",
    "edf.select(\"DEST_COUNTRY_NAME\", \"ORIGIN_COUNTRY_NAME\").show(2)\n",
    "\n",
    "edf.select(\n",
    "    expr(\"DEST_COUNTRY_NAME\"),\n",
    "    col(\"DEST_COUNTRY_NAME\"),\n",
    "    column(\"DEST_COUNTRY_NAME\"))\\\n",
    "    .show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": [
     "8"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|  destination|\n",
      "+-------------+\n",
      "|United States|\n",
      "|United States|\n",
      "+-------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edf.select(expr(\"DEST_COUNTRY_NAME AS destination\")).show(2)\n",
    "\n",
    "edf.select(\n",
    "        expr(\"DEST_COUNTRY_NAME as destination\").alias(\"DEST_COUNTRY_NAME\")\n",
    "    ).show(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": [
     "9"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "|newColumnName|DEST_COUNTRY_NAME|\n",
      "+-------------+-----------------+\n",
      "|United States|    United States|\n",
      "|United States|    United States|\n",
      "+-------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------+---------------------------------+\n",
      "| avg(count)|count(DISTINCT DEST_COUNTRY_NAME)|\n",
      "+-----------+---------------------------------+\n",
      "|1770.765625|                              132|\n",
      "+-----------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edf.selectExpr(\"DEST_COUNTRY_NAME as newColumnName\", \"DEST_COUNTRY_NAME\").show(2)\n",
    "\n",
    "# SELECT *, (DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME) as withinCountryFROM edf LIMIT 2\n",
    "edf.selectExpr(\n",
    "    \"*\", # all original columns\n",
    "    \"(DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME) as withinCountry\")\\\n",
    ".show(2)\n",
    "\n",
    "# SELECT avg(count), count(distinct(DEST_COUNTRY_NAME)) FROM edf LIMIT 2\n",
    "edf.selectExpr(\"avg(count)\", \"count(distinct(DEST_COUNTRY_NAME))\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "10"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|One|\n",
      "+-----------------+-------------------+-----+---+\n",
      "|    United States|            Romania|   15|  1|\n",
      "|    United States|            Croatia|    1|  1|\n",
      "+-----------------+-------------------+-----+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# SELECT *, 1 as One FROM edf LIMIT 2\n",
    "edf.select(expr(\"*\"), lit(1).alias(\"One\")).show(2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
